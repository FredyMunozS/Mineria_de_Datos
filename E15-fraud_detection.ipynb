{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>1.387210e+05</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "      <td>138721.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>408.456679</td>\n",
       "      <td>0.865017</td>\n",
       "      <td>1.224018</td>\n",
       "      <td>92.411768</td>\n",
       "      <td>57.280717</td>\n",
       "      <td>3.852491</td>\n",
       "      <td>3.468364</td>\n",
       "      <td>4.427882</td>\n",
       "      <td>4.287014</td>\n",
       "      <td>72.623256</td>\n",
       "      <td>3.806588</td>\n",
       "      <td>2.389925e+03</td>\n",
       "      <td>236.033152</td>\n",
       "      <td>2.816048</td>\n",
       "      <td>4.768151</td>\n",
       "      <td>0.005745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>711.300625</td>\n",
       "      <td>0.604681</td>\n",
       "      <td>11.235396</td>\n",
       "      <td>1105.622216</td>\n",
       "      <td>806.837009</td>\n",
       "      <td>2.023177</td>\n",
       "      <td>2.127371</td>\n",
       "      <td>0.994649</td>\n",
       "      <td>0.992454</td>\n",
       "      <td>271.189458</td>\n",
       "      <td>1.039490</td>\n",
       "      <td>4.998821e+04</td>\n",
       "      <td>998.162648</td>\n",
       "      <td>1.497330</td>\n",
       "      <td>0.363702</td>\n",
       "      <td>0.075580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.154151</td>\n",
       "      <td>-0.154151</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265703</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887303</td>\n",
       "      <td>0.716678</td>\n",
       "      <td>3.817305</td>\n",
       "      <td>3.811097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.356462</td>\n",
       "      <td>8.479000e+01</td>\n",
       "      <td>85.190000</td>\n",
       "      <td>1.408767</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>4.422139</td>\n",
       "      <td>4.497450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.114614</td>\n",
       "      <td>1.399900e+02</td>\n",
       "      <td>139.990000</td>\n",
       "      <td>2.929287</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>497.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.992339</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>4.453620</td>\n",
       "      <td>2.395100e+02</td>\n",
       "      <td>199.754240</td>\n",
       "      <td>3.865009</td>\n",
       "      <td>4.962055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>505.000000</td>\n",
       "      <td>258877.420000</td>\n",
       "      <td>258877.420000</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>5.561934</td>\n",
       "      <td>4019.593056</td>\n",
       "      <td>4.874212</td>\n",
       "      <td>8.999998e+06</td>\n",
       "      <td>132568.670000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accountAge  digitalItemCount  sumPurchaseCount1Day  \\\n",
       "count  138721.000000     138721.000000         138721.000000   \n",
       "mean      408.456679          0.865017              1.224018   \n",
       "std       711.300625          0.604681             11.235396   \n",
       "min         1.000000          0.000000              0.000000   \n",
       "25%         1.000000          1.000000              0.000000   \n",
       "50%         1.000000          1.000000              0.000000   \n",
       "75%       497.000000          1.000000              0.000000   \n",
       "max      2000.000000         29.000000            505.000000   \n",
       "\n",
       "       sumPurchaseAmount1Day  sumPurchaseAmount30Day  \\\n",
       "count          138721.000000           138721.000000   \n",
       "mean               92.411768               57.280717   \n",
       "std              1105.622216              806.837009   \n",
       "min                 0.000000                0.000000   \n",
       "25%                 0.000000                0.000000   \n",
       "50%                 0.000000                0.000000   \n",
       "75%                 0.000000                0.000000   \n",
       "max            258877.420000           258877.420000   \n",
       "\n",
       "       paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "count                                 138721.000000   \n",
       "mean                                       3.852491   \n",
       "std                                        2.023177   \n",
       "min                                       -0.154151   \n",
       "25%                                        0.887303   \n",
       "50%                                        5.064533   \n",
       "75%                                        5.064533   \n",
       "max                                        5.412885   \n",
       "\n",
       "       accountPostalCode - LogOddsForClass_0  \\\n",
       "count                          138721.000000   \n",
       "mean                                3.468364   \n",
       "std                                 2.127371   \n",
       "min                                -0.154151   \n",
       "25%                                 0.716678   \n",
       "50%                                 5.096396   \n",
       "75%                                 5.096396   \n",
       "max                                 5.096396   \n",
       "\n",
       "       paymentBillingState - LogOddsForClass_0  \\\n",
       "count                            138721.000000   \n",
       "mean                                  4.427882   \n",
       "std                                   0.994649   \n",
       "min                                   0.265703   \n",
       "25%                                   3.817305   \n",
       "50%                                   4.422139   \n",
       "75%                                   5.563677   \n",
       "max                                   5.563677   \n",
       "\n",
       "       accountState - LogOddsForClass_0  paymentInstrumentAgeInAccount  \\\n",
       "count                     138721.000000                  138721.000000   \n",
       "mean                           4.287014                      72.623256   \n",
       "std                            0.992454                     271.189458   \n",
       "min                            0.342945                       0.000000   \n",
       "25%                            3.811097                       0.000000   \n",
       "50%                            4.497450                       0.000000   \n",
       "75%                            4.992339                       0.029861   \n",
       "max                            5.561934                    4019.593056   \n",
       "\n",
       "       ipState - LogOddsForClass_0  transactionAmount  transactionAmountUSD  \\\n",
       "count                138721.000000       1.387210e+05         138721.000000   \n",
       "mean                      3.806588       2.389925e+03            236.033152   \n",
       "std                       1.039490       4.998821e+04            998.162648   \n",
       "min                       0.265703       1.000000e-02              0.000000   \n",
       "25%                       3.356462       8.479000e+01             85.190000   \n",
       "50%                       4.114614       1.399900e+02            139.990000   \n",
       "75%                       4.453620       2.395100e+02            199.754240   \n",
       "max                       4.874212       8.999998e+06         132568.670000   \n",
       "\n",
       "       ipPostalCode - LogOddsForClass_0  localHour - LogOddsForClass_0  \\\n",
       "count                     138721.000000                  138721.000000   \n",
       "mean                           2.816048                       4.768151   \n",
       "std                            1.497330                       0.363702   \n",
       "min                            0.182322                       0.421214   \n",
       "25%                            1.408767                       4.745402   \n",
       "50%                            2.929287                       4.886641   \n",
       "75%                            3.865009                       4.962055   \n",
       "max                            5.008490                       5.040929   \n",
       "\n",
       "               Label  \n",
       "count  138721.000000  \n",
       "mean        0.005745  \n",
       "std         0.075580  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression and a Decision Tree and Random fOREST\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accountAge                                        int64\n",
       "digitalItemCount                                  int64\n",
       "sumPurchaseCount1Day                              int64\n",
       "sumPurchaseAmount1Day                           float64\n",
       "sumPurchaseAmount30Day                          float64\n",
       "paymentBillingPostalCode - LogOddsForClass_0    float64\n",
       "accountPostalCode - LogOddsForClass_0           float64\n",
       "paymentBillingState - LogOddsForClass_0         float64\n",
       "accountState - LogOddsForClass_0                float64\n",
       "paymentInstrumentAgeInAccount                   float64\n",
       "ipState - LogOddsForClass_0                     float64\n",
       "transactionAmount                               float64\n",
       "transactionAmountUSD                            float64\n",
       "ipPostalCode - LogOddsForClass_0                float64\n",
       "localHour - LogOddsForClass_0                   float64\n",
       "Label                                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Label']\n",
    "X = df.drop(['Label'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    137924\n",
       "1       797\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'cumulative explained variance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA().fit(X_train_s)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con 10 variables es posible explican el 80% de la variabilidad los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13439751 0.11322615 0.09854674 0.09204775 0.07350127 0.06884543\n",
      " 0.06683842 0.06272319 0.06024085 0.058123  ]\n",
      "Total explanation:  0.8284903056008418\n"
     ]
    }
   ],
   "source": [
    "# Instanciate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components = 10)\n",
    "# Fit PCA on training set\n",
    "pca.fit(X_train_s)\n",
    "# Apply the mapping (transform) to both the training set and the test set.\n",
    "X_train = pca.transform(X_train_s)\n",
    "X_test = pca.transform(X_test_s)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Total explanation: \",sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9939709030538687\n",
      "F1-score: 0.0\n",
      "F_Beta-Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train,y_train)\n",
    "y_pred=lreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "\n",
    "accuracy_scores.append(['none','reg-log', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9883350080824851\n",
      "F1-score: 0.06643356643356645\n",
      "F_Beta-Score: 0.06402001668056714\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "y_pred=dtree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "\n",
    "accuracy_scores.append(['none','d-tree', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9937087684040369\n",
      "F1-score: 0.03355704697986577\n",
      "F_Beta-Score: 0.19611650485436893\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test))\n",
    "print(\"F1-score:\",metrics.f1_score(y_pred, y_test))\n",
    "print(\"F_Beta-Score:\",metrics.fbeta_score(y_pred, y_test,10))\n",
    "\n",
    "accuracy_scores.append(['none','random forest', -1, -1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9908252872558871 F1-Score: 0.09482758620689655 F-Beta: 0.11588005215123857\n",
      "Accuracy: 0.9827428022194067 F1-Score: 0.07925407925407926 F-Beta: 0.05862569355527103\n",
      "Accuracy: 0.9628642579404955 F1-Score: 0.05450500556173526 F-Beta: 0.032436506636080616\n",
      "Accuracy: 0.9369566167154528 F1-Score: 0.04563492063492063 F-Beta: 0.025325701826110655\n",
      "Accuracy: 0.9145877932631395 F1-Score: 0.03931203931203931 F-Beta: 0.021275755381475872\n",
      "Accuracy: 0.8676438463890952 F1-Score: 0.033498165576647 F-Beta: 0.017684579147037974\n",
      "Accuracy: 0.8380881646205601 F1-Score: 0.02882599580712788 F-Beta: 0.015095621454533102\n",
      "Accuracy: 0.8101708244134738 F1-Score: 0.02556627046422965 F-Beta: 0.013317525952057369\n",
      "Accuracy: 0.7436541570186552 F1-Score: 0.024116424116424118 F-Beta: 0.01246091340324605\n",
      "Accuracy: 0.7037004674734588 F1-Score: 0.0233294930875576 F-Beta: 0.012016965646402143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for target_percentage in np.arange(0.05,0.55, 0.05):\n",
    "    X_u, y_u = UnderSampling(X_train, y_train, target_percentage, 1)\n",
    "    lreg.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','reg-log',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    dtree.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','d-tree',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    rf.fit(X_u,y_u)\n",
    "    y_pred=rf.predict(X_test)\n",
    "    accuracy_scores.append(['under-sampling','random forest',target_percentage,-1,metrics.accuracy_score(y_pred, y_test), metrics.f1_score(y_pred, y_test),metrics.fbeta_score(y_pred, y_test,10)])   \n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_pred, y_test),\"F1-Score:\",metrics.f1_score(y_pred, y_test),\"F-Beta:\",metrics.fbeta_score(y_pred, y_test,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Label']\n",
    "X = df.drop(['Label'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "models = {'Logistic Regression': LogisticRegression(),\n",
    "          'Decision Tree': DecisionTreeClassifier(),\n",
    "          'RandomForest': RandomForestClassifier(),\n",
    "          'SVM': LinearSVC(dual=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_s=[]\n",
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    X_train, y_train = OverSampling(X.values, y, target_percentage, 1)\n",
    "    y_pred_new = pd.DataFrame (columns =models.keys(),index= y_test.index )\n",
    "    for i, model  in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_new[i] = model.predict(X_test) \n",
    "    for model in models.keys():\n",
    "        ac_s.append([model, target_percentage, accuracy_score(y_pred_new[model], y_test), f1_score(y_pred_new[model], y_test), fbeta_score(y_pred_new[model], y_test, beta=10)])\n",
    "ac_s = pd.DataFrame(ac_s, columns=['Model', 'target_percentage', 'Acc', 'F1 Score', 'FBeta Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>target_percentage</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>FBeta Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.993993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.993320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.988394</td>\n",
       "      <td>0.051081</td>\n",
       "      <td>0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>0.039595</td>\n",
       "      <td>0.022384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.944123</td>\n",
       "      <td>0.895099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.967633</td>\n",
       "      <td>0.046709</td>\n",
       "      <td>0.028476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.909100</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.021312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.891872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.926016</td>\n",
       "      <td>0.032065</td>\n",
       "      <td>0.017530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.552635</td>\n",
       "      <td>0.019486</td>\n",
       "      <td>0.009968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.944123</td>\n",
       "      <td>0.895099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.486820</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.009389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.397914</td>\n",
       "      <td>0.017719</td>\n",
       "      <td>0.009034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.313934</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.008213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.247904</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.944123</td>\n",
       "      <td>0.895099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.201504</td>\n",
       "      <td>0.014239</td>\n",
       "      <td>0.007243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.161472</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.006928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.155129</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>0.006876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.006017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.898348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999231</td>\n",
       "      <td>0.938697</td>\n",
       "      <td>0.885489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.005971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  target_percentage       Acc  F1 Score  FBeta Score\n",
       "0   Logistic Regression                0.1  0.993993  0.000000     0.000000\n",
       "1         Decision Tree                0.1  0.999327  0.945946     0.898348\n",
       "2          RandomForest                0.1  0.999327  0.945946     0.898348\n",
       "3                   SVM                0.1  0.993921  0.000000     0.000000\n",
       "4   Logistic Regression                0.2  0.993320  0.000000     0.000000\n",
       "5         Decision Tree                0.2  0.999327  0.945946     0.898348\n",
       "6          RandomForest                0.2  0.999327  0.945946     0.898348\n",
       "7                   SVM                0.2  0.988394  0.051081     0.049278\n",
       "8   Logistic Regression                0.3  0.947545  0.039595     0.022384\n",
       "9         Decision Tree                0.3  0.999327  0.945946     0.898348\n",
       "10         RandomForest                0.3  0.999303  0.944123     0.895099\n",
       "11                  SVM                0.3  0.967633  0.046709     0.028476\n",
       "12  Logistic Regression                0.4  0.909100  0.039604     0.021312\n",
       "13        Decision Tree                0.4  0.999327  0.945946     0.898348\n",
       "14         RandomForest                0.4  0.999279  0.942308     0.891872\n",
       "15                  SVM                0.4  0.926016  0.032065     0.017530\n",
       "16  Logistic Regression                0.5  0.552635  0.019486     0.009968\n",
       "17        Decision Tree                0.5  0.999327  0.945946     0.898348\n",
       "18         RandomForest                0.5  0.999303  0.944123     0.895099\n",
       "19                  SVM                0.5  0.486820  0.018385     0.009389\n",
       "20  Logistic Regression                0.6  0.397914  0.017719     0.009034\n",
       "21        Decision Tree                0.6  0.999327  0.945946     0.898348\n",
       "22         RandomForest                0.6  0.999327  0.945946     0.898348\n",
       "23                  SVM                0.6  0.313934  0.016127     0.008213\n",
       "24  Logistic Regression                0.7  0.247904  0.014918     0.007591\n",
       "25        Decision Tree                0.7  0.999327  0.945946     0.898348\n",
       "26         RandomForest                0.7  0.999303  0.944123     0.895099\n",
       "27                  SVM                0.7  0.201504  0.014239     0.007243\n",
       "28  Logistic Regression                0.8  0.161472  0.013624     0.006928\n",
       "29        Decision Tree                0.8  0.999327  0.945946     0.898348\n",
       "30         RandomForest                0.8  0.999327  0.945946     0.898348\n",
       "31                  SVM                0.8  0.155129  0.013523     0.006876\n",
       "32  Logistic Regression                0.9  0.017733  0.011845     0.006017\n",
       "33        Decision Tree                0.9  0.999327  0.945946     0.898348\n",
       "34         RandomForest                0.9  0.999231  0.938697     0.885489\n",
       "35                  SVM                0.9  0.010164  0.011755     0.005971"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()  \n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__ = np.random.choice(k, n_samples_1_new)\n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1][sel] - step * (X[y==1][sel] - X[y==1][nn_])\n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_s =[]\n",
    "for target_percentage in [0.25, 0.5]:\n",
    "    for k in [5, 15]:\n",
    "        X_sm, y_sm = SMOTE(X.values, y, target_percentage, k, seed=3)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.30, random_state=42)\n",
    "        for key, value  in models.items():\n",
    "            value.fit(X_train, y_train)\n",
    "            y_pred = value.predict(X_test) \n",
    "            ac_s.append([key, target_percentage, k, accuracy_score(y_pred, y_test), f1_score(y_pred, y_test), fbeta_score(y_pred, y_test, beta=10)])\n",
    "ac_s = pd.DataFrame(ac_s, columns=['Model', 'target_percentage','k', 'Acc', 'F1 Score', 'FBeta Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>target_percentage</th>\n",
       "      <th>k</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>FBeta Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.788617</td>\n",
       "      <td>0.467245</td>\n",
       "      <td>0.646018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.984067</td>\n",
       "      <td>0.968733</td>\n",
       "      <td>0.967283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992152</td>\n",
       "      <td>0.984388</td>\n",
       "      <td>0.996182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.774588</td>\n",
       "      <td>0.380862</td>\n",
       "      <td>0.623975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.749955</td>\n",
       "      <td>0.172018</td>\n",
       "      <td>0.523191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.980714</td>\n",
       "      <td>0.962003</td>\n",
       "      <td>0.964298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.987874</td>\n",
       "      <td>0.975679</td>\n",
       "      <td>0.995654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>0.743883</td>\n",
       "      <td>0.061379</td>\n",
       "      <td>0.402484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.793076</td>\n",
       "      <td>0.789626</td>\n",
       "      <td>0.808554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989088</td>\n",
       "      <td>0.989175</td>\n",
       "      <td>0.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994417</td>\n",
       "      <td>0.994434</td>\n",
       "      <td>0.998348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.754867</td>\n",
       "      <td>0.745885</td>\n",
       "      <td>0.779499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.50</td>\n",
       "      <td>15</td>\n",
       "      <td>0.683644</td>\n",
       "      <td>0.665568</td>\n",
       "      <td>0.710590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.50</td>\n",
       "      <td>15</td>\n",
       "      <td>0.984110</td>\n",
       "      <td>0.984221</td>\n",
       "      <td>0.984256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.50</td>\n",
       "      <td>15</td>\n",
       "      <td>0.992073</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>0.997204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.50</td>\n",
       "      <td>15</td>\n",
       "      <td>0.667537</td>\n",
       "      <td>0.660681</td>\n",
       "      <td>0.679230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  target_percentage   k       Acc  F1 Score  \\\n",
       "0   Logistic Regression               0.25   5  0.788617  0.467245   \n",
       "1         Decision Tree               0.25   5  0.984067  0.968733   \n",
       "2          RandomForest               0.25   5  0.992152  0.984388   \n",
       "3                   SVM               0.25   5  0.774588  0.380862   \n",
       "4   Logistic Regression               0.25  15  0.749955  0.172018   \n",
       "5         Decision Tree               0.25  15  0.980714  0.962003   \n",
       "6          RandomForest               0.25  15  0.987874  0.975679   \n",
       "7                   SVM               0.25  15  0.743883  0.061379   \n",
       "8   Logistic Regression               0.50   5  0.793076  0.789626   \n",
       "9         Decision Tree               0.50   5  0.989088  0.989175   \n",
       "10         RandomForest               0.50   5  0.994417  0.994434   \n",
       "11                  SVM               0.50   5  0.754867  0.745885   \n",
       "12  Logistic Regression               0.50  15  0.683644  0.665568   \n",
       "13        Decision Tree               0.50  15  0.984110  0.984221   \n",
       "14         RandomForest               0.50  15  0.992073  0.992088   \n",
       "15                  SVM               0.50  15  0.667537  0.660681   \n",
       "\n",
       "    FBeta Score  \n",
       "0      0.646018  \n",
       "1      0.967283  \n",
       "2      0.996182  \n",
       "3      0.623975  \n",
       "4      0.523191  \n",
       "5      0.964298  \n",
       "6      0.995654  \n",
       "7      0.402484  \n",
       "8      0.808554  \n",
       "9      0.988281  \n",
       "10     0.998348  \n",
       "11     0.779499  \n",
       "12     0.710590  \n",
       "13     0.984256  \n",
       "14     0.997204  \n",
       "15     0.679230  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 96811, 1: 96202})\n",
      "\n",
      "Logistic Regression :\n",
      "F1 Score:  0.6932659751706347\n",
      "Accurancy:  0.6550210950061048\n",
      "FBeta Score:  0.6282707354578471\n",
      "\n",
      "Decision Tree :\n",
      "F1 Score:  0.9888931535767403\n",
      "Accurancy:  0.9888057446114046\n",
      "FBeta Score:  0.9870827651346322\n",
      "\n",
      "RandomForest :\n",
      "F1 Score:  0.995884476534296\n",
      "Accurancy:  0.995865620580022\n",
      "FBeta Score:  0.9972489791944655\n",
      "\n",
      "SVM :\n",
      "F1 Score:  0.6951652354931043\n",
      "Accurancy:  0.6459544734710654\n",
      "FBeta Score:  0.6145416765968674\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN \n",
    "ada = ADASYN(random_state=42)\n",
    "X_ada, y_ada = ada.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ada, y_ada, test_size=0.30, random_state=42)\n",
    "print('Resampled dataset shape %s' % Counter(y_train))\n",
    "for key, value  in models.items():\n",
    "    value.fit(X_train, y_train.ravel())\n",
    "    y_pred = value.predict(X_test)\n",
    "    print()\n",
    "    print(key,':')\n",
    "    print('F1 Score: ', f1_score(y_pred, y_test))\n",
    "    print('Accurancy: ', accuracy_score(y_pred, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_pred, y_test, beta=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aunque los resultados de las técnicas son diferentes, resulta interesante encontrar los algoritmos ya implementados en la librería imblearn. \n",
    "\n",
    "Con este tipo de técnicas han resultado mas favorables los resultados del modelo de regresión logística. Y a nivel de UnderSanmpling el random forest ha presentado mejores resultados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
